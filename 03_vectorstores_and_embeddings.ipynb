{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorstores and Embeddings\n",
    "\n",
    "Recall the overall workflow for retrieval augmented generation (RAG):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just discussed `Document Loading` and `Splitting`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"D:/Professional/Hackules/paper/modelEfficient.pdf\"),\n",
    "    PyPDFLoader(\"D:/Professional/Hackules/paper/modelEfficient.pdf\"),\n",
    "    PyPDFLoader(\"D:/Professional/Hackules/paper/modelEfficient.pdf\"),\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Let's take our splits and embed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure modes\n",
    "\n",
    "This seems great, and basic similarity search will get you 80% of the way there very easily. \n",
    "\n",
    "But there are some failure modes that can creep up. \n",
    "\n",
    "Here are some edge cases that can arise - we'll fix them in the next class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we're getting duplicate chunks (because of the duplicate `MachineLearning-Lecture01.pdf` in the index).\n",
    "\n",
    "Semantic search fetches all similar documents, but does not enforce diversity.\n",
    "\n",
    "`docs[0]` and `docs[1]` are indentical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Efficient Deep Learning: A Survey on Making Deep Learning\\nModels Smaller, Faster, and Better\\nGAURAV MENGHANI, Google Research, USA\\nDeep Learning has revolutionized the fields of computer vision, natural language understanding, speech recog-\\nnition, information retrieval and more. However, with the progressive improvements in deep learning models,\\ntheir number of parameters, latency, resources required to train, etc. have all have increased significantly.\\nConsequently, it has become important to pay attention to these footprint metrics of a model as well, not just\\nits quality. We present and motivate the problem of efficiency in deep learning, followed by a thorough survey\\nof the five core areas of model efficiency (spanning modeling techniques, infrastructure, and hardware) and the\\nseminal work there. We also present an experiment-based guide along with code, for practitioners to optimize\\ntheir model training and deployment. We believe this is the first comprehensive survey in the efficient deep\\nlearning space that covers the landscape of model efficiency from modeling techniques to hardware support.\\nOur hope is that this survey would provide the reader with the mental model and the necessary understanding\\nof the field to apply generic efficiency techniques to immediately get significant improvements, and also equip\\nthem with ideas for further research and experimentation to achieve additional gains.\\n1 INTRODUCTION\\nDeep Learning with neural networks has been the dominant methodology of training new machine\\nlearning models for the past decade. Its rise to prominence is often attributed to the ImageNet\\ncompetition [ 45] in 2012. That year, a University of Toronto team submitted a deep convolutional\\nnetwork (AlexNet [ 92], named after the lead developer Alex Krizhevsky), performed 41% better\\nthan the next best submission. As a result of this trailblazing work, there was a race to create\\ndeeper networks with an ever increasing number of parameters and complexity. Several model\\narchitectures such as VGGNet [ 141], Inception [ 146], ResNet [ 73] etc. successively beat previous\\nrecords at ImageNet competitions in the subsequent years, while also increasing in their footprint\\n(model size, latency, etc.)\\nThis effect has also been noted in natural language understanding (NLU), where the Transformer\\n[155] architecture based on primarily Attention layers, spurred the development of general purpose\\nlanguage encoders like BERT [ 47], GPT-3 [ 26], etc. BERT specifically beat 11 NLU benchmarks\\nwhen it was published. GPT-3 has also been used in several places in the industry via its API. The\\ncommon aspect amongst these domains is the rapid growth in the model footprint (Refer to Figure\\n1), and the cost associated with training and deploying them.\\nSince deep learning research has been focused on improving the state of the art, progressive\\nimprovements on benchmarks like image classification, text classification, etc. have been correlated\\nwith an increase in the network complexity, number of parameters, the amount of training resources\\nrequired to train the network, prediction latency, etc. For instance, GPT-3 comprises of 175 billion\\nparameters, and costs millions of dollars to train just one iteration ([ 26]). This excludes the cost of\\nexperimentation / trying combinations of different hyper-parameters, which is also computationally\\nexpensive.\\nWhile these models perform well on the tasks they are trained on, they might not necessarily be\\nefficient enough for direct deployment in the real world. A deep learning practitioner might face\\nthe following challenges when training or deploying a model.\\n•Sustainable Server-Side Scaling : Training and deploying large deep learning models is\\ncostly. While training could be a one-time cost (or could be free if one is using a pre-trained\\nmodel), deploying and letting inference run for over a long period of time could still turn\\nAuthor’s address: Gaurav Menghani, gmenghani@google.com, Google Research, Mountain View, California, USA, 95054.arXiv:2106.08962v2  [cs.LG]  21 Jun 2021', metadata={'source': 'D:/Professional/Hackules/paper/modelEfficient.pdf', 'page': 0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='2 Gaurav Menghani\\n(a) Computer Vision Models\\n(b) Natural Language Models\\nFig. 1. Growth in the number of parameters in Computer Vision models over time. [118]\\nout to be expensive in terms of consumption of server-side RAM, CPU, etc.. There is also\\na very real concern around the carbon footprint of datacenters even for organizations like\\nGoogle, Facebook, Amazon, etc. which spend several billion dollars each per year in capital\\nexpenditure on their data-centers.\\n•Enabling On-Device Deployment : Certain deep learning applications need to run realtime\\non IoT and smart devices (where the model inference happens directly on the device), for a\\nmultitude of reasons (privacy, connectivity, responsiveness). Thus, it becomes imperative to\\noptimize the models for the target devices.\\n•Privacy & Data Sensitivity : Being able to use as little data as possible for training is critical\\nwhen the user-data might be sensitive. Hence, efficiently training models with a fraction of\\nthe data means lesser data-collection required.\\n•New Applications : Certain new applications offer new constraints (around model quality\\nor footprint) that existing off-the-shelf models might not be able to address.\\n•Explosion of Models : While a singular model might work well, training and/or deploying\\nmultiple models on the same infrastructure (colocation) for different applications might end\\nup exhausting the available resources.', metadata={'source': 'D:/Professional/Hackules/paper/modelEfficient.pdf', 'page': 1})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a new failure mode.\n",
    "\n",
    "The question below asks a question about the third lecture, but includes results from other lectures as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[4].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
