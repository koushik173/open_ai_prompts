{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import openapi_key\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = openapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "# name = llm.predict(\"Generate some indian food items with cucomber\")\n",
    "# print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "# prompt_template_name = PromptTemplate(\n",
    "#     input_variables=['vegetable'],\n",
    "#     template = \"Generate food items with {vegetable}. Suggest indian food items\"\n",
    "# )\n",
    "# promptt = prompt_template_name.format(vegetable=\"apple\")\n",
    "# items = llm.predict(promptt)\n",
    "# print(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains with llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# chain = LLMChain(llm=llm, prompt =prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Banana Chutney \n",
      "2. Banana Halwa \n",
      "3. Banana Lassi \n",
      "4. Banana Kheer \n",
      "5. Banana Fry \n",
      "6. Banana Poori \n",
      "7. Banana Appam \n",
      "8. Banana Roti \n",
      "9. Banana Pakora \n",
      "10. Banana Kofta Curry\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"banana\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Input and One output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your task is generate food recipe step by \n",
      "step below format with give food=Italian\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recepi_prompt = PromptTemplate(\n",
    "    input_variables=['foodItem'],\n",
    "    template=f\"\"\"\n",
    "Your task is generate food recipe step by \n",
    "step below format with give food=`{{foodItem}}`\n",
    "\"\"\"\n",
    ")\n",
    "p = recepi_prompt.format(foodItem=\"Italian\")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "foodItems_prompt = PromptTemplate(\n",
    "    input_variables=['vegetable'],\n",
    "    template='Generate only one indian food item with {vegetable}'\n",
    ")\n",
    "nameChain = LLMChain(llm=llm, prompt=foodItems_prompt)\n",
    "\n",
    "recepi_prompt = PromptTemplate(\n",
    "    input_variables=['foodItem'],\n",
    "    template=f\"\"\"\n",
    "Your task is generate food recipe step by \n",
    "step below format with give food=`{{foodItem}}`\n",
    "\"\"\"\n",
    ")\n",
    "recepiPrompt = LLMChain(llm=llm, prompt=recepi_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Peel and chop 2 ripe bananas into small pieces.\n",
      "\n",
      "2. Place chopped banana in a bowl and add 2 cups of plain yogurt.\n",
      "\n",
      "3. Add 1/2 teaspoon of ground cardamom and 1/4 teaspoon of ground cinnamon.\n",
      "\n",
      "4. Stir until all the ingredients are combined.\n",
      "\n",
      "5. Add 1 tablespoon of honey or sugar (optional).\n",
      "\n",
      "6. Refrigerate until ready to serve.\n",
      "\n",
      "7. Serve chilled with your favorite meal. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains = [nameChain, recepiPrompt])\n",
    "\n",
    "content = chain.run(\"Banana\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muktiple Input and moultiple Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0.9)\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "foodItems_prompt = PromptTemplate(\n",
    "    input_variables=['vegetable'],\n",
    "    template='Generate only one indian food item with {vegetable}'\n",
    ")\n",
    "nameChain = LLMChain(llm=llm, prompt=foodItems_prompt, output_key=\"foodItem\")\n",
    "\n",
    "recepi_prompt = PromptTemplate(\n",
    "    input_variables=['foodItem'],\n",
    "    template=f\"\"\"\n",
    "Your task is generate food recipe step by \n",
    "step below format with give food=`{{foodItem}}`\n",
    "\"\"\"\n",
    ")\n",
    "recepiPrompt = LLMChain(llm=llm, prompt=recepi_prompt, output_key=\"recipe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vegetable': 'Banana', 'foodItem': '\\n\\nBanana Dosa', 'recipe': '\\n1. Peel and mash 3-4 ripe bananas.\\n2. In a bowl mix the mashed banana with a pinch of salt, ½ teaspoon of cumin powder, ½ teaspoon of chili powder and 1 teaspoon of oil.\\n3. Add ¾ to 1 cup of rice flour.\\n4. Gradually add water and mix everything into a batter of medium thick consistency.\\n5. Heat a flat non-stick pan on medium heat and pour a ladle full of batter.\\n6. Spread the batter evenly to form a thin dosa.\\n7. Sprinkle a few drops of oil and cook the dosa on medium-low heat till it turns golden brown.\\n8. Flip the dosa and cook the other side for a few seconds.\\n9. Serve the banana dosa hot with chutney or sambar.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [nameChain, recepiPrompt],\n",
    "    input_variables = ['vegetable'],\n",
    "    output_variables = ['foodItem', \"recipe\"]\n",
    ")\n",
    "content = chain(\"Banana\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vegetable': 'Banana', 'foodItem': '\\n\\nBanana Dosa', 'recipe': '\\n1. Peel and mash 3-4 ripe bananas.\\n2. In a bowl mix the mashed banana with a pinch of salt, ½ teaspoon of cumin powder, ½ teaspoon of chili powder and 1 teaspoon of oil.\\n3. Add ¾ to 1 cup of rice flour.\\n4. Gradually add water and mix everything into a batter of medium thick consistency.\\n5. Heat a flat non-stick pan on medium heat and pour a ladle full of batter.\\n6. Spread the batter evenly to form a thin dosa.\\n7. Sprinkle a few drops of oil and cook the dosa on medium-low heat till it turns golden brown.\\n8. Flip the dosa and cook the other side for a few seconds.\\n9. Serve the banana dosa hot with chutney or sambar.'}\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "step =content['recipe'].strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 1. Peel and mash 3-4 ripe bananas.\n",
      "-- 2. In a bowl mix the mashed banana with a pinch of salt, ½ teaspoon of cumin powder, ½ teaspoon of chili powder and 1 teaspoon of oil.\n",
      "-- 3. Add ¾ to 1 cup of rice flour.\n",
      "-- 4. Gradually add water and mix everything into a batter of medium thick consistency.\n",
      "-- 5. Heat a flat non-stick pan on medium heat and pour a ladle full of batter.\n",
      "-- 6. Spread the batter evenly to form a thin dosa.\n",
      "-- 7. Sprinkle a few drops of oil and cook the dosa on medium-low heat till it turns golden brown.\n",
      "-- 8. Flip the dosa and cook the other side for a few seconds.\n",
      "-- 9. Serve the banana dosa hot with chutney or sambar.\n"
     ]
    }
   ],
   "source": [
    "for item in step:\n",
    "    print(\"--\",item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secret_key import serpapi_key\n",
    "import os\n",
    "os.environ['SERPER_API_KEY'] = serpapi_key\n",
    "# os.environ['OPENAI_API_KEY'] = openapi_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serpapi and llm-math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5aad7363c865e81b95ef714b5b83509261326dcfb7959f69128988af1668ac24\n"
     ]
    }
   ],
   "source": [
    "print(serpapi_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the location of the venue\n",
      "Action: Search\n",
      "Action Input: \"World Cup Cricket 2023 Venue\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIndia\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-davinci-003 in organization org-4h1riewe2DAzat5ygUYh2tZV on requests per min (RPM): Limit 3, Used 3, Requested 1. Please try again in 20s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The venue of the World Cup Cricket final match in 2023 is India.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The venue of the World Cup Cricket final match in 2023 is India.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "agent.run(\"Where is the vanue of world cup cricket final match in 2023?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install this package: pip install wikipedia\n",
    "\n",
    "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Let's test it out!\n",
    "agent.run(\"When was Elon musk born? What is his age right now in 2023?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Apple Halwa\n",
      "2. Apple Kheer\n",
      "3. Apple Pachadi\n",
      "4. Apple Payasam\n",
      "5. Apple Chutney\n",
      "6. Apple Curry\n",
      "7. Apple Raita\n",
      "8. Apple Kebab\n",
      "9. Apple Kofta\n",
      "10. Apple Pulao\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['vegetable'],\n",
    "    template = \"Generate food items with {vegetable}. Suggest indian food items\"\n",
    ")\n",
    "promptt = prompt_template_name.format(vegetable=\"apple\")\n",
    "items = llm.predict(promptt)\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt =prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Banana Halwa\n",
      "2. Banana Sheera\n",
      "3. Banana Appam\n",
      "4. Banana Payasam\n",
      "5. Banana Raita\n",
      "6. Banana Kofta Curry\n",
      "7. Banana Chips\n",
      "8. Banana Bread\n",
      "9. Banana Smoothie\n",
      "10. Banana Lassi\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"banana\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Jackfruit Biryani\n",
      "2. Jackfruit Curry\n",
      "3. Jackfruit Kebab\n",
      "4. Jackfruit Tikka Masala\n",
      "5. Jackfruit Pulao\n",
      "6. Jackfruit Pakora\n",
      "7. Jackfruit Samosa\n",
      "8. Jackfruit Dal\n",
      "9. Jackfruit Raita\n",
      "10. Jackfruit Halwa\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"jackfood\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Rajma Chawal\n",
      "2. Chana Masala\n",
      "3. Dal Makhani\n",
      "4. Moong Dal Tadka\n",
      "5. Matar Paneer\n",
      "6. Aloo Chole\n",
      "7. Chole Bhature\n",
      "8. Masala Vada\n",
      "9. Dal Fry\n",
      "10. Vegetable Biryani\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.run(\"Beans\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Cucumber Raita\n",
      "2. Cucumber Pachadi\n",
      "3. Cucumber Kebab\n",
      "4. Cucumber Salad\n",
      "5. Cucumber Samosa\n",
      "6. Cucumber Pakora\n",
      "7. Cucumber Kofta Curry\n",
      "8. Cucumber and Coconut Chutney\n",
      "9. Cucumber and Mint Raita\n",
      "10. Cucumber and Onion Bhaji\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"Cucomber\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Beans\n",
      "AI: \n",
      "\n",
      "1. Rajma Chawal\n",
      "2. Chana Masala\n",
      "3. Dal Makhani\n",
      "4. Moong Dal Tadka\n",
      "5. Matar Paneer\n",
      "6. Aloo Chole\n",
      "7. Chole Bhature\n",
      "8. Masala Vada\n",
      "9. Dal Fry\n",
      "10. Vegetable Biryani\n",
      "Human: Cucomber\n",
      "AI: \n",
      "\n",
      "1. Cucumber Raita\n",
      "2. Cucumber Pachadi\n",
      "3. Cucumber Kebab\n",
      "4. Cucumber Salad\n",
      "5. Cucumber Samosa\n",
      "6. Cucumber Pakora\n",
      "7. Cucumber Kofta Curry\n",
      "8. Cucumber and Coconut Chutney\n",
      "9. Cucumber and Mint Raita\n",
      "10. Cucumber and Onion Bhaji\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
