{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to students.\n",
    "During periods of high load you may find the notebook unresponsive. It may appear to execute a cell, update the completion number in brackets [#] at the left of the cell but you may find the cell has not executed. This is particularly obvious on print statements when there is no output.\n",
    "If this happens, restart the kernel using the command under the Kernel tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFs\n",
    "\n",
    "Let's load a PDF [transcript](https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf) from Andrew Ng's famous CS229 course! These documents are the result of automated transcription so words and sentences are sometimes split unexpectedly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The course will show the pip installs you would need to install packages on your own machine.\n",
    "# These packages are already installed on this platform and should not be run again.\n",
    "#! pip install pypdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"D:/Professional/Hackules/paper/modelEfficient.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficient Deep Learning: A Survey on Making Deep Learning\n",
      "Models Smaller, Faster, and Better\n",
      "GAURAV MENGHANI, Google Research, USA\n",
      "Deep Learning has revolutionized the fields of computer vision, natural language understanding, speech recog-\n",
      "nition, information retrieval and more. However, with the progressive improvements in deep learning models,\n",
      "their number of parameters, latency, resources required to train, etc. have all have increased significantly.\n",
      "Consequently, it has become important to \n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'D:/Professional/Hackules/paper/modelEfficient.pdf', 'page': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Youtube video\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=MDA3LUKNl1E\n",
      "[youtube] MDA3LUKNl1E: Downloading webpage\n",
      "[youtube] MDA3LUKNl1E: Downloading ios player API JSON\n",
      "[youtube] MDA3LUKNl1E: Downloading android player API JSON\n",
      "[youtube] MDA3LUKNl1E: Downloading m3u8 information\n",
      "[info] MDA3LUKNl1E: Downloading 1 format(s): 140\n",
      "[download] Destination: D:\\Professional\\Hackules\\paper\\Fine-tuning Llama 2 on Your Own Dataset ｜ Train an LLM for Your Use Case with QLoRA on a Single GPU.m4a\n",
      "[download] 100% of   17.10MiB in 00:00:03 at 4.65MiB/s   \n",
      "[FixupM4a] Correcting container of \"D:\\Professional\\Hackules\\paper\\Fine-tuning Llama 2 on Your Own Dataset ｜ Train an LLM for Your Use Case with QLoRA on a Single GPU.m4a\"\n",
      "[ExtractAudio] Not converting audio D:\\Professional\\Hackules\\paper\\Fine-tuning Llama 2 on Your Own Dataset ｜ Train an LLM for Your Use Case with QLoRA on a Single GPU.m4a; file is already in target format m4a\n",
      "Transcribing part 1!\n",
      "Transcribing part 1!\n",
      "Transcribing part 2!\n",
      "Transcribing part 3!\n",
      "Transcribing part 4!\n",
      "Transcribing part 1!\n",
      "Transcribing part 2!\n",
      "Transcribing part 3!\n",
      "Transcribing part 4!\n",
      "Transcribing part 1!\n",
      "Transcribing part 2!\n",
      "Transcribing part 3!\n",
      "Transcribing part 4!\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.youtube.com/watch?v=MDA3LUKNl1E\"\n",
    "save_dir=\"D:/Professional/Hackules/paper/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir), \n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15558"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = docs[0].page_content[2001:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is summarized below lecture that delimited by triple \n",
    "backticks in at most 100 words. And find out major key points.\n",
    "Dont make any assumptions out of this lecture.\n",
    "\n",
    "output format:\n",
    "1. <details one major key point>\n",
    "2. <details one major key point>\n",
    "3. <details one major key point>\n",
    ".\n",
    ".\n",
    ".\n",
    "Lecture: ```{ll}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The benefits of fine-tuning a large-language model include improved performance on specific tasks and reduced need for prompt engineering.\n",
      "2. Fine-tuning a large-language model can be challenging and resource-intensive, requiring a lot of time and high-quality data.\n",
      "3. Fine-tuning may not work as well as the general large-language model when used with external knowledge or in retrieval augmented generation.\n",
      "4. The lecture provides an example of how to fine-tune a large-language model, LLAMA 2.0, to summarize conversations on Twitter between customer support agents and users.\n",
      "5. A complete text tutorial and code examples for fine-tuning LLAMA 2.0 on a custom dataset are available on mlexpert.io, but only for ML Expert Pro subscribers.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.thedailystar.net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22124"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
